{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(host, user, password, database):\n",
    "    try:\n",
    "        # Establish a database connection\n",
    "        conn = mysql.connector.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            database=database\n",
    "        )\n",
    "\n",
    "        # Create a cursor object\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute a query to retrieve table names\n",
    "        query = f\"SELECT table_name FROM INFORMATION_SCHEMA.TABLES WHERE table_schema = '{database}'\"\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch all the rows\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        # Print table names\n",
    "        # for (table_name,) in tables:\n",
    "        #     print(table_name)\n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(f\"Error: {error}\")\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_to_dataframe(host, user, password, database, table_name):\n",
    "    try:\n",
    "        # Establish a database connection\n",
    "        conn = mysql.connector.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            database=database\n",
    "        )\n",
    "\n",
    "        # Use backticks around the table name in the query\n",
    "        query = f\"SELECT * FROM `{table_name}`\"\n",
    "\n",
    "        # Use pandas to read the query into a DataFrame\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            df = pd.read_sql(query, conn)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except mysql.connector.Error as error:\n",
    "        print(f\"Error: {error}\")\n",
    "        return None\n",
    "    finally:\n",
    "        if conn.is_connected():\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000440', '005290', '009620', '009730', '013990', '021080', '024060', '025320', '027360', '027830', '029480', '033540', '036540', '036630', '038870', '041020', '041190', '041460', '047310', '048770', '049080', '050890', '053050', '056080', '057680', '058610', '059100', '060250', '060280', '060310', '064260', '065350', '065450', '066790', '068760', '072950', '080220', '080530', '085670', '086960', '088800', '090150', '090360', '090710', '094170', '094480', '096630', '098460', '099440', '104480', '108490', '115160', '117730', '129890', '136480', '142210', '203650', '205100', '205470', '207760', '208340', '214270', '214680', '215100', '218150', '227100', '228760', '232140', '241820', '253590', '254120', '264850', '270520', '270660', '277070', '290690', '291230', '293580', '299900', '306620', '307930', '317830', '319400', '321260', '321370', '348340', '356680', '380540', '382800', '383930', '388790', '391710', '403870', '417200', '419050', '419270', '450520', '452190', '452300', '900250']\n"
     ]
    }
   ],
   "source": [
    "# databaseA = \"A\" + datetime.now().strftime(\"%Y%m%d\") \n",
    "databaseA = 'a20240112'\n",
    "password = '93150lbm!!'\n",
    "\n",
    "tables = get_table_names('127.0.0.1', 'root', password, databaseA)\n",
    "\n",
    "tables = [code for (code,) in tables]\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>체결시간</th>\n",
       "      <th>현재가</th>\n",
       "      <th>거래량</th>\n",
       "      <th>거래대금</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>time_diff_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-12 09:41:33.012765</td>\n",
       "      <td>18750</td>\n",
       "      <td>39</td>\n",
       "      <td>731250</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-12 09:41:36.405014</td>\n",
       "      <td>18740</td>\n",
       "      <td>-5</td>\n",
       "      <td>-93700</td>\n",
       "      <td>0 days 00:00:03.392249</td>\n",
       "      <td>3.392249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-12 09:41:37.399747</td>\n",
       "      <td>18740</td>\n",
       "      <td>1</td>\n",
       "      <td>18740</td>\n",
       "      <td>0 days 00:00:00.994733</td>\n",
       "      <td>0.994733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-12 09:41:43.996522</td>\n",
       "      <td>18730</td>\n",
       "      <td>-146</td>\n",
       "      <td>-2734580</td>\n",
       "      <td>0 days 00:00:06.596775</td>\n",
       "      <td>6.596775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-12 09:41:46.801512</td>\n",
       "      <td>18740</td>\n",
       "      <td>20</td>\n",
       "      <td>374800</td>\n",
       "      <td>0 days 00:00:02.804990</td>\n",
       "      <td>2.804990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896</th>\n",
       "      <td>8895</td>\n",
       "      <td>2024-01-12 15:19:52.595263</td>\n",
       "      <td>18960</td>\n",
       "      <td>303</td>\n",
       "      <td>5744880</td>\n",
       "      <td>0 days 00:00:00.001522</td>\n",
       "      <td>0.001522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8897</th>\n",
       "      <td>8898</td>\n",
       "      <td>2024-01-12 15:19:55.805188</td>\n",
       "      <td>18920</td>\n",
       "      <td>-30</td>\n",
       "      <td>-567600</td>\n",
       "      <td>0 days 00:00:03.209925</td>\n",
       "      <td>3.209925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8898</th>\n",
       "      <td>8899</td>\n",
       "      <td>2024-01-12 15:19:57.598681</td>\n",
       "      <td>18960</td>\n",
       "      <td>1</td>\n",
       "      <td>18960</td>\n",
       "      <td>0 days 00:00:01.793493</td>\n",
       "      <td>1.793493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>8900</td>\n",
       "      <td>2024-01-12 15:30:25.579565</td>\n",
       "      <td>19090</td>\n",
       "      <td>7559</td>\n",
       "      <td>144301310</td>\n",
       "      <td>0 days 00:10:27.980884</td>\n",
       "      <td>627.980884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>8901</td>\n",
       "      <td>2024-01-12 15:39:58.365123</td>\n",
       "      <td>19090</td>\n",
       "      <td>161</td>\n",
       "      <td>3073490</td>\n",
       "      <td>0 days 00:09:32.785558</td>\n",
       "      <td>572.785558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8901 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                       체결시간    현재가   거래량       거래대금  \\\n",
       "0        1 2024-01-12 09:41:33.012765  18750    39     731250   \n",
       "1        2 2024-01-12 09:41:36.405014  18740    -5     -93700   \n",
       "2        3 2024-01-12 09:41:37.399747  18740     1      18740   \n",
       "3        4 2024-01-12 09:41:43.996522  18730  -146   -2734580   \n",
       "4        5 2024-01-12 09:41:46.801512  18740    20     374800   \n",
       "...    ...                        ...    ...   ...        ...   \n",
       "8896  8895 2024-01-12 15:19:52.595263  18960   303    5744880   \n",
       "8897  8898 2024-01-12 15:19:55.805188  18920   -30    -567600   \n",
       "8898  8899 2024-01-12 15:19:57.598681  18960     1      18960   \n",
       "8899  8900 2024-01-12 15:30:25.579565  19090  7559  144301310   \n",
       "8900  8901 2024-01-12 15:39:58.365123  19090   161    3073490   \n",
       "\n",
       "                  time_diff  time_diff_seconds  \n",
       "0                       NaT                NaN  \n",
       "1    0 days 00:00:03.392249           3.392249  \n",
       "2    0 days 00:00:00.994733           0.994733  \n",
       "3    0 days 00:00:06.596775           6.596775  \n",
       "4    0 days 00:00:02.804990           2.804990  \n",
       "...                     ...                ...  \n",
       "8896 0 days 00:00:00.001522           0.001522  \n",
       "8897 0 days 00:00:03.209925           3.209925  \n",
       "8898 0 days 00:00:01.793493           1.793493  \n",
       "8899 0 days 00:10:27.980884         627.980884  \n",
       "8900 0 days 00:09:32.785558         572.785558  \n",
       "\n",
       "[8901 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = tables[0]\n",
    "\n",
    "df = table_to_dataframe('127.0.0.1', 'root', password, databaseA, code)\n",
    "df['체결시간'] = pd.to_datetime(df['체결시간'])\n",
    "df['현재가'] = pd.to_numeric(df['현재가'].str.replace('+','').str.replace('-',''), errors='coerce')\n",
    "df['거래량'] = pd.to_numeric(df['거래량'], errors='coerce')\n",
    "df['거래대금'] = df['현재가'] * df['거래량']\n",
    "df = df.sort_values(by='체결시간', ignore_index=True)\n",
    "df['time_diff'] = df['체결시간'].diff()\n",
    "df['time_diff_seconds'] = df['time_diff'].dt.total_seconds()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>거래대금</th>\n",
       "      <th>time_diff_seconds</th>\n",
       "      <th>현재가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-93700</td>\n",
       "      <td>3.392249</td>\n",
       "      <td>18740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18740</td>\n",
       "      <td>0.994733</td>\n",
       "      <td>18740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2734580</td>\n",
       "      <td>6.596775</td>\n",
       "      <td>18730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374800</td>\n",
       "      <td>2.804990</td>\n",
       "      <td>18740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896</th>\n",
       "      <td>5744880</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>18960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8897</th>\n",
       "      <td>-567600</td>\n",
       "      <td>3.209925</td>\n",
       "      <td>18920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8898</th>\n",
       "      <td>18960</td>\n",
       "      <td>1.793493</td>\n",
       "      <td>18960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>144301310</td>\n",
       "      <td>627.980884</td>\n",
       "      <td>19090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>3073490</td>\n",
       "      <td>572.785558</td>\n",
       "      <td>19090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8901 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           거래대금  time_diff_seconds    현재가\n",
       "0        731250                NaN  18750\n",
       "1        -93700           3.392249  18740\n",
       "2         18740           0.994733  18740\n",
       "3      -2734580           6.596775  18730\n",
       "4        374800           2.804990  18740\n",
       "...         ...                ...    ...\n",
       "8896    5744880           0.001522  18960\n",
       "8897    -567600           3.209925  18920\n",
       "8898      18960           1.793493  18960\n",
       "8899  144301310         627.980884  19090\n",
       "8900    3073490         572.785558  19090\n",
       "\n",
       "[8901 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use = df[['거래대금', 'time_diff_seconds', '현재가']]\n",
    "df_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    def __init__(self, df, window_size=50, initial_budget=10000000):\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.df = df.dropna()\n",
    "        self.window_size = window_size\n",
    "        self.initial_budget = initial_budget\n",
    "        self.current_budget = initial_budget\n",
    "        self.action_space = gym.spaces.Discrete(3)  # ['buy', 'hold', 'sell']\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(window_size, 3), dtype=np.float32)\n",
    "        self.holding_stock = False\n",
    "        self.stock_amount = 0\n",
    "        self.buy_price = 0\n",
    "        self.current_step = window_size\n",
    "        self.holding_status_history = [0] * window_size  # Initialize with no stock held\n",
    "        self.invalid_action_penalty = -0.0001\n",
    "        self.prev_price = 0 \n",
    "\n",
    "\n",
    "    def update_holding_status(self):\n",
    "        \"\"\"\n",
    "        Update the holding status history.\n",
    "        Add 1 if holding stock, 0 otherwise.\n",
    "        \"\"\"\n",
    "        if len(self.holding_status_history) >= self.window_size:\n",
    "            self.holding_status_history.pop(0)  # Remove the oldest status\n",
    "        self.holding_status_history.append(1 if self.holding_stock else 0)\n",
    "\n",
    "    def sell_all_stocks(self):\n",
    "        \"\"\"\n",
    "        Sell all held stocks at the current price.\n",
    "        This method is called at the end of each episode.\n",
    "        \"\"\"\n",
    "        if self.holding_stock:\n",
    "            current_price = self.df.iloc[self.current_step, 2]  # 현재가\n",
    "            sell_amount = self.stock_amount * current_price\n",
    "            self.current_budget += sell_amount\n",
    "            self.stock_amount = 0\n",
    "            self.holding_stock = False\n",
    "            \n",
    "    def step(self, action):\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        current_price = self.df.iloc[self.current_step, 2]  # 현재가\n",
    "\n",
    "        if action == 0 : #buy \n",
    "            if self.holding_stock:\n",
    "                self.reward = self.invalid_action_penalty\n",
    "            else : \n",
    "                self.stock_amount = self.current_budget // current_price\n",
    "                if self.stock_amount > 0:\n",
    "                    self.holding_stock = True\n",
    "                    self.buy_price = current_price\n",
    "                    self.current_budget -= self.stock_amount * current_price\n",
    "                    \n",
    "        elif action == 1 and self.holding_stock : # hold\n",
    "            \n",
    "            self.reward = (current_price - self.buy_price) / self.buy_price \n",
    "            \n",
    "\n",
    "\n",
    "        elif action == 2 :  # Sell\n",
    "            if not self.holding_stock:\n",
    "                self.reward = self.invalid_action_penalty\n",
    "            else :\n",
    "                self.holding_stock = False\n",
    "                sell_amount = self.stock_amount * current_price\n",
    "                self.reward = (sell_amount - self.buy_price * self.stock_amount) / (self.buy_price * self.stock_amount) \n",
    "                self.current_budget += sell_amount\n",
    "                self.stock_amount = 0\n",
    "\n",
    "        self.update_holding_status()\n",
    "\n",
    "        if self.current_step >= len(self.df)-1:\n",
    "            self.done = True  # End the episode when there are no more steps\n",
    "            self.sell_all_stocks() \n",
    "        else : \n",
    "            self.current_step += 1\n",
    "\n",
    "        self.prev_price = current_price\n",
    "        \n",
    "        return self._next_observation(), self.reward, self.done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = self.window_size\n",
    "        self.current_budget = self.initial_budget\n",
    "        self.holding_stock = False\n",
    "        self.stock_amount = 0\n",
    "        self.buy_price = 0\n",
    "        self.holding_status_history = [0] * self.window_size\n",
    "\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        start = self.current_step - self.window_size\n",
    "        end = self.current_step\n",
    "        obs = self.df.iloc[start:end, [0, 1]].values\n",
    "        \n",
    "        holding_status = np.array(self.holding_status_history).reshape(-1, 1)\n",
    "        obs_with_holding_status = np.hstack((obs, holding_status))\n",
    "        return obs_with_holding_status\n",
    "\n",
    "    # Additional methods as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, num_classes, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output.mean(dim=1))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerPolicy(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, num_actions):\n",
    "        super(TransformerPolicy, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = nn.Embedding(50, d_model)  # Assuming max length 50\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, num_actions)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.encoder(src)\n",
    "        position = torch.arange(0, src.size(1), device=src.device).unsqueeze(0).repeat(src.size(0), 1)\n",
    "        pos_encoded = self.pos_encoder(position)\n",
    "        src += pos_encoded\n",
    "        output = self.transformer_encoder(src)\n",
    "        logits = self.decoder(output.mean(dim=1))\n",
    "        stabilized_logits = logits - torch.max(logits, dim=1, keepdim=True).values\n",
    "        return F.softmax(stabilized_logits, dim=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimplePolicy(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimplePolicy, self).__init__()\n",
    "        # Define the architecture\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.softmax(self.fc3(x), dim=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_observation(observation):\n",
    "#     \"\"\"\n",
    "#     Process the observation for the model.\n",
    "#     \"\"\"\n",
    "#     # Check if the observation is already a tensor\n",
    "#     if isinstance(observation, torch.Tensor):\n",
    "#         # If it's a tensor, just ensure it's on the correct device\n",
    "#         return observation.to(device)\n",
    "#     else:\n",
    "#         # If it's not a tensor (e.g., numpy array or list), convert it to a tensor and move to the device\n",
    "#         return torch.tensor(observation, dtype=torch.float32).to(device)\n",
    "\n",
    "# def process_observation(observation):\n",
    "#     \"\"\"\n",
    "#     Process the observation for the model.\n",
    "#     \"\"\"\n",
    "#     # Flatten the observation\n",
    "#     flattened_obs = observation.flatten()\n",
    "\n",
    "#     # Check if the observation is already a tensor\n",
    "#     if isinstance(flattened_obs, torch.Tensor):\n",
    "#         # If it's a tensor, just ensure it's on the correct device\n",
    "#         return flattened_obs.to(device)\n",
    "#     else:\n",
    "#         # If it's not a tensor (e.g., numpy array or list), convert it to a tensor and move to the device\n",
    "#         return torch.tensor(flattened_obs, dtype=torch.float32).to(device)\n",
    "\n",
    "def process_observation(observation):\n",
    "    # Assuming observation is a flat vector of features\n",
    "    # Reshape or process it to match [sequence_length, embed_size]\n",
    "    processed_obs = observation.view(-1, embed_size)  # Adjust as needed\n",
    "    return processed_obs.to(device)\n",
    "\n",
    "def select_action(model, state):\n",
    "    state_tensor = process_observation(state)\n",
    "    state_tensor = state_tensor.unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        action_probs = model(state_tensor)\n",
    "    action = torch.multinomial(action_probs, 1).item()\n",
    "    return action\n",
    "\n",
    "\n",
    "\n",
    "# def select_action(model, state):\n",
    "#     # Convert state to a tensor if it's a numpy array or a list\n",
    "#     if isinstance(state, np.ndarray) or isinstance(state, list):\n",
    "#         state_tensor = torch.FloatTensor(state).to(device)\n",
    "#     elif isinstance(state, torch.Tensor):\n",
    "#         # If it's already a tensor, ensure it's on the correct device\n",
    "#         state_tensor = state.to(device)\n",
    "#     else:\n",
    "#         raise TypeError(\"Unrecognized type for state. Expected numpy array, list, or torch.Tensor\")\n",
    "\n",
    "#     state_tensor = state_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "#     with torch.no_grad():\n",
    "#         action_probs = model(state_tensor)\n",
    "#         print(\"Action probabilities:\", action_probs)\n",
    "#     action = torch.multinomial(action_probs, 1).item()\n",
    "#     return action\n",
    "\n",
    "# def select_action(model, state):\n",
    "#     state_tensor = process_observation(state)\n",
    "#     with torch.no_grad():\n",
    "#         action_probs = model(state_tensor)\n",
    "#     action = torch.multinomial(action_probs, 1).item()\n",
    "#     return action\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_returns(rewards, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Compute discounted returns.\n",
    "    \"\"\"\n",
    "    R = 0\n",
    "    returns = []\n",
    "    for r in reversed(rewards):\n",
    "        R = r + gamma * R\n",
    "        returns.insert(0, R)\n",
    "    return returns\n",
    "\n",
    "def update_model(observations, actions, returns, optimizer):\n",
    "    \"\"\"\n",
    "    Perform a policy gradient update using a batch of training data.\n",
    "    \"\"\"\n",
    "    observations = torch.stack(observations)\n",
    "    actions = torch.tensor(actions)\n",
    "    returns = torch.tensor(returns)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    log_probs = torch.log(model(observations))\n",
    "    selected_log_probs = log_probs[range(len(actions)), actions]\n",
    "    loss = -torch.mean(selected_log_probs * returns)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        \n",
    "        \n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "        \n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        N = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "\n",
    "        # Split the embedding into self.heads pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        queries = self.queries(queries)\n",
    "        keys = self.keys(keys)\n",
    "        values = self.values(values)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attention = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys]) / self.embed_size**0.5\n",
    "        if mask is not None:\n",
    "            attention = attention.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        attention = torch.nn.functional.softmax(attention, dim=3)\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadSelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.LeakyReLU(0.05),  # Replaced ReLU with LeakyReLU\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.norm1(attention + query)\n",
    "        x = self.dropout(x)\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.norm2(forward + x)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    \"\"\"\n",
    "    Compute the positional encoding for a given position and model size.\n",
    "    \"\"\"\n",
    "    def _calc_freq(position, i):\n",
    "        return position / torch.pow(10000, 2 * (i // 2) / d_model)\n",
    "    \n",
    "    position = torch.arange(position).unsqueeze(1).float()\n",
    "    div_term = torch.arange(0, d_model, 2).float()\n",
    "    \n",
    "    # Apply sin to even positions in the array; 2i\n",
    "    pe = torch.zeros([position.shape[0], d_model])\n",
    "    pe[:, 0::2] = torch.sin(_calc_freq(position, div_term))\n",
    "    \n",
    "    # Apply cos to odd positions in the array; 2i+1\n",
    "    pe[:, 1::2] = torch.cos(_calc_freq(position, div_term))\n",
    "    \n",
    "    return pe\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, embed_size, num_layers, heads, forward_expansion, max_length, dropout):\n",
    "        super(GPT, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.model_type = 'GPT'\n",
    "        self.classification_head = nn.Linear(embed_size, 1)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Using the model's device\n",
    "        device = next(self.parameters()).device\n",
    "        self.pe = positional_encoding(max_length, embed_size).to(device)\n",
    "\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        N, seq_length, _ = x.shape\n",
    "        \n",
    "        out = self.dropout(x + self.pe[:x.size(1), :])  # Use sinusoidal positional encoding\n",
    "\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        # Take the output from the last token in the sequence\n",
    "        seq_last_output = out[:, -1, :]\n",
    "        logits = self.classification_head(seq_last_output)\n",
    "        \n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Initialize the trading environment\n",
    "env = TradingEnv(df_use)  # Assuming df is your DataFrame\n",
    "\n",
    "# # Initialize the Transformer policy model\n",
    "# input_dim = 3  # Adjust this based on your environment's observation space\n",
    "# model = TransformerPolicy(input_dim=input_dim, d_model=64, nhead=2, num_layers=2, num_actions=3)\n",
    "\n",
    "embed_size = 150  # Size of each embedding vector\n",
    "num_layers = 2    # Number of Transformer blocks\n",
    "heads = 5         # Number of attention heads\n",
    "forward_expansion = 4\n",
    "max_length = 50   # Max length of the sequence\n",
    "dropout = 0.1\n",
    "\n",
    "model = GPT(embed_size, num_layers, heads, forward_expansion, max_length, dropout).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m episode_actions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 14\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     next_observation, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     17\u001b[0m     episode_rewards\u001b[38;5;241m.\u001b[39mappend(reward)\n",
      "Cell \u001b[1;32mIn[22], line 35\u001b[0m, in \u001b[0;36mselect_action\u001b[1;34m(model, state)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_action\u001b[39m(model, state):\n\u001b[1;32m---> 35\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     state_tensor \u001b[38;5;241m=\u001b[39m state_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[1;32mIn[22], line 31\u001b[0m, in \u001b[0;36mprocess_observation\u001b[1;34m(observation)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_observation\u001b[39m(observation):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Assuming observation is a flat vector of features\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Reshape or process it to match [sequence_length, embed_size]\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     processed_obs \u001b[38;5;241m=\u001b[39m \u001b[43mobservation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed_obs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "gamma = 0.99  # Discount factor for future rewards\n",
    "accumulation_steps = 100\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    observation = env.reset()\n",
    "    observation = torch.FloatTensor(observation).to(device)  # Move observation to GPU\n",
    "    done = False\n",
    "    episode_rewards = []\n",
    "    episode_observations = []\n",
    "    episode_actions = []\n",
    "\n",
    "    while not done:\n",
    "        action = select_action(model, observation)\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "\n",
    "        episode_rewards.append(reward)\n",
    "        episode_observations.append(process_observation(observation))\n",
    "        episode_actions.append(action)\n",
    "\n",
    "        observation = next_observation\n",
    "\n",
    "    returns = compute_returns(episode_rewards, gamma)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    for i, (observation, action, return_) in enumerate(zip(episode_observations, episode_actions, returns)):\n",
    "        log_probs = torch.log(model(observation.unsqueeze(0)))\n",
    "        selected_log_probs = log_probs[0, action]\n",
    "        loss = -selected_log_probs * return_\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0 or i == len(episode_observations) - 1:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    total_reward = sum(episode_rewards)\n",
    "    initial_budget = env.initial_budget\n",
    "    current_budget = env.current_budget\n",
    "    return_rate = (current_budget - initial_budget) / initial_budget * 100\n",
    "    print(f\"Episode {episode+1}, Total Reward: {total_reward}, Return {return_rate:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
